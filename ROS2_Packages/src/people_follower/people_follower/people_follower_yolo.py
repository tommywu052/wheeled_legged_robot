#!/usr/bin/env python3
"""
RealSenseäººé«”è¿½è¹¤ç¯€é» - YOLOv8ç‰ˆæœ¬
ä½¿ç”¨YOLOv8é€²è¡Œé«˜æº–ç¢ºåº¦äººé«”åµæ¸¬ï¼Œæ”¯æ´Jetson GPUåŠ é€Ÿ

è¨‚é–±è©±é¡Œï¼š
  - /camera/camera/color/image_raw (RGBå½±åƒ)
  - /camera/camera/aligned_depth_to_color/image_raw (å°é½Šçš„æ·±åº¦å½±åƒ)

ç™¼ä½ˆè©±é¡Œï¼š
  - /cmd_vel (æ§åˆ¶æ©Ÿå™¨äººé‹å‹•)
  - /people_follower/debug_image (é™¤éŒ¯è¦–è¦ºåŒ–å½±åƒ)
  - /people_follower/status (è¿½è¹¤ç‹€æ…‹)
"""

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import Twist
from std_msgs.msg import String
from cv_bridge import CvBridge
import cv2
import numpy as np
import time

# YOLOv8ç›¸é—œå°å…¥
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("âš ï¸  YOLOv8æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip3 install ultralytics")


class PeopleFollowerYOLO(Node):
    """åŸºæ–¼YOLOv8çš„äººé«”è¿½è¹¤ç¯€é»"""
    
    def __init__(self):
        super().__init__('people_follower_yolo')
        
        if not YOLO_AVAILABLE:
            self.get_logger().error('âŒ YOLOv8æœªå®‰è£ï¼è«‹åŸ·è¡Œ: pip3 install ultralytics')
            return
        
        # ========== åƒæ•¸å®£å‘Š ==========
        self.declare_parameter('yolo_model', 'yolov8n.pt')  # yolov8n(å¿«) / yolov8s(æº–)
        self.declare_parameter('target_distance', 1.0)
        self.declare_parameter('min_distance', 0.5)
        self.declare_parameter('max_distance', 3.0)
        self.declare_parameter('max_linear_speed', 0.3)
        self.declare_parameter('max_angular_speed', 0.8)
        self.declare_parameter('linear_gain', 0.5)
        self.declare_parameter('angular_gain', 2.0)
        self.declare_parameter('enable_follower', True)
        self.declare_parameter('publish_debug_image', True)
        self.declare_parameter('confidence_threshold', 0.5)  # YOLOä¿¡å¿ƒé–¾å€¼
        
        # ç²å–åƒæ•¸
        yolo_model = self.get_parameter('yolo_model').value
        self.target_distance = self.get_parameter('target_distance').value
        self.min_distance = self.get_parameter('min_distance').value
        self.max_distance = self.get_parameter('max_distance').value
        self.max_linear_speed = self.get_parameter('max_linear_speed').value
        self.max_angular_speed = self.get_parameter('max_angular_speed').value
        self.linear_gain = self.get_parameter('linear_gain').value
        self.angular_gain = self.get_parameter('angular_gain').value
        self.enable_follower = self.get_parameter('enable_follower').value
        self.publish_debug_image = self.get_parameter('publish_debug_image').value
        self.confidence_threshold = self.get_parameter('confidence_threshold').value
        
        # ========== åˆå§‹åŒ–è®Šæ•¸ ==========
        self.bridge = CvBridge()
        self.latest_color_image = None
        self.latest_depth_image = None
        self.camera_info = None
        self.image_width = 640
        self.image_height = 480
        self.last_detection_time = time.time()
        self.no_person_timeout = 2.0
        
        # ========== åˆå§‹åŒ–YOLOv8æ¨¡å‹ ==========
        self.get_logger().info(f'ğŸ“¦ è¼‰å…¥YOLOæ¨¡å‹: {yolo_model}')
        try:
            self.model = YOLO(yolo_model)
            # Jetsonå„ªåŒ–ï¼šä½¿ç”¨FP16
            self.model.fuse()  # èåˆå±¤ä»¥æå‡é€Ÿåº¦
            self.get_logger().info('âœ… YOLOv8æ¨¡å‹å·²è¼‰å…¥')
            self.get_logger().info(f'   ä½¿ç”¨è£ç½®: {"CUDA" if self.model.device.type == "cuda" else "CPU"}')
        except Exception as e:
            self.get_logger().error(f'âŒ YOLOæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}')
            return
        
        # ========== QoSè¨­ç½® ==========
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            history=HistoryPolicy.KEEP_LAST,
            depth=1
        )
        
        # ========== è¨‚é–±è€… ==========
        self.color_sub = self.create_subscription(
            Image,
            '/camera/camera/color/image_raw',
            self.color_callback,
            qos_profile
        )
        
        self.depth_sub = self.create_subscription(
            Image,
            '/camera/camera/aligned_depth_to_color/image_raw',
            self.depth_callback,
            qos_profile
        )
        
        self.camera_info_sub = self.create_subscription(
            CameraInfo,
            '/camera/camera/color/camera_info',
            self.camera_info_callback,
            10
        )
        
        # ========== ç™¼ä½ˆè€… ==========
        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        self.debug_image_pub = self.create_publisher(Image, '/people_follower/debug_image', 10)
        self.status_pub = self.create_publisher(String, '/people_follower/status', 10)
        
        # ========== å®šæ™‚å™¨ ==========
        self.timer = self.create_timer(0.1, self.process_callback)  # 10Hz
        
        self.get_logger().info('ğŸš€ YOLOv8äººé«”è¿½è¹¤ç¯€é»å·²å•Ÿå‹•')
        self.get_logger().info(f'   æ¨¡å‹: {yolo_model}')
        self.get_logger().info(f'   ç›®æ¨™è·é›¢: {self.target_distance}m')
        self.get_logger().info(f'   è¿½è¹¤å•Ÿç”¨: {self.enable_follower}')
    
    def color_callback(self, msg):
        """RGBå½±åƒå›èª¿"""
        try:
            self.latest_color_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
            self.image_height, self.image_width = self.latest_color_image.shape[:2]
        except Exception as e:
            self.get_logger().error(f'RGBå½±åƒè½‰æ›å¤±æ•—: {e}')
    
    def depth_callback(self, msg):
        """æ·±åº¦å½±åƒå›èª¿"""
        try:
            self.latest_depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f'æ·±åº¦å½±åƒè½‰æ›å¤±æ•—: {e}')
    
    def camera_info_callback(self, msg):
        """ç›¸æ©Ÿåƒæ•¸å›èª¿"""
        if self.camera_info is None:
            self.camera_info = msg
            self.get_logger().info('âœ… ç›¸æ©Ÿåƒæ•¸å·²æ¥æ”¶')
    
    def detect_people_yolo(self, image):
        """ä½¿ç”¨YOLOv8åµæ¸¬äººé«”"""
        # YOLOæ¨ç†
        results = self.model(image, verbose=False, conf=self.confidence_threshold)
        
        detections = []
        for r in results:
            boxes = r.boxes
            for box in boxes:
                # åªä¿ç•™personé¡åˆ¥ (class_id = 0 in COCO)
                if int(box.cls) == 0:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf)
                    
                    detections.append({
                        'bbox': (int(x1), int(y1), int(x2-x1), int(y2-y1)),
                        'confidence': confidence,
                        'center_x': int((x1 + x2) / 2),
                        'center_y': int((y1 + y2) / 2)
                    })
        
        return detections
    
    def get_depth_at_point(self, x, y, depth_image, window_size=9):
        """ç²å–æŒ‡å®šé»çš„æ·±åº¦å€¼ï¼ˆæ”¹é€²ç‰ˆï¼šæ›´å¤§çª—å£ï¼Œæ›´ç©©å®šï¼‰"""
        if depth_image is None:
            return None
        
        h, w = depth_image.shape
        
        # ç¢ºä¿åº§æ¨™åœ¨æœ‰æ•ˆç¯„åœå…§
        x = int(np.clip(x, 0, w - 1))
        y = int(np.clip(y, 0, h - 1))
        
        # ä½¿ç”¨æ›´å¤§çš„çª—å£ï¼ˆ9x9ï¼‰æé«˜ç©©å®šæ€§
        half_window = window_size // 2
        y_min = max(0, y - half_window)
        y_max = min(h, y + half_window + 1)
        x_min = max(0, x - half_window)
        x_max = min(w, x + half_window + 1)
        
        # æå–çª—å£
        window = depth_image[y_min:y_max, x_min:x_max]
        
        # éæ¿¾ç„¡æ•ˆå€¼ï¼ˆ0è¡¨ç¤ºç„¡æ·±åº¦ï¼‰
        valid_depths = window[window > 0]
        
        # å¦‚æœæœ‰æ•ˆæ·±åº¦å¤ªå°‘ï¼Œæ“´å¤§æœç´¢ç¯„åœ
        if len(valid_depths) < 3:
            # å˜—è©¦æ›´å¤§çš„çª—å£ï¼ˆ15x15ï¼‰
            larger_half = 7
            y_min = max(0, y - larger_half)
            y_max = min(h, y + larger_half + 1)
            x_min = max(0, x - larger_half)
            x_max = min(w, x + larger_half + 1)
            
            window = depth_image[y_min:y_max, x_min:x_max]
            valid_depths = window[window > 0]
        
        if len(valid_depths) == 0:
            return None
        
        # ä½¿ç”¨ä¸­ä½æ•¸ï¼ˆæ¯”å¹³å‡å€¼æ›´ç©©å®šï¼‰
        return np.median(valid_depths) / 1000.0
    
    def select_target_person(self, detections, depth_image):
        """é¸æ“‡ç›®æ¨™äººç‰©ï¼ˆæ”¹é€²ç‰ˆï¼šæ›´å¥½çš„é‚Šç·£è™•ç†ï¼‰"""
        if len(detections) == 0:
            return None
        
        valid_targets = []
        
        for i, detection in enumerate(detections):
            center_x = detection['center_x']
            center_y = detection['center_y']
            bbox = detection['bbox']
            
            # æª¢æŸ¥æª¢æ¸¬æ¡†æ˜¯å¦åœ¨ç•«é¢å…§
            x, y, w, h = bbox
            if x < 0 or y < 0 or (x + w) > self.image_width or (y + h) > self.image_height:
                # é‚Šç•Œæ¡†éƒ¨åˆ†è¶…å‡ºï¼Œèª¿æ•´ä¸­å¿ƒé»åˆ°æ¡†å…§æœ‰æ•ˆå€åŸŸ
                center_x = int(np.clip(center_x, 10, self.image_width - 10))
                center_y = int(np.clip(center_y, 10, self.image_height - 10))
                self.get_logger().debug(f'æª¢æ¸¬æ¡†{i}éƒ¨åˆ†è¶…å‡ºç•«é¢ï¼Œèª¿æ•´ä¸­å¿ƒé»: ({center_x}, {center_y})')
            
            # ç²å–æ·±åº¦
            depth = self.get_depth_at_point(center_x, center_y, depth_image)
            
            if depth is None or depth <= 0:
                self.get_logger().debug(f'æª¢æ¸¬æ¡†{i}ç„¡æ³•ç²å–æœ‰æ•ˆæ·±åº¦')
                continue
            
            # éæ¿¾è¶…å‡ºç¯„åœçš„åµæ¸¬ï¼ˆåªéæ¿¾å¤ªé çš„ï¼Œå¤ªè¿‘çš„ä»è¦è¿½è¹¤ä»¥ä¾¿å¾Œé€€ï¼‰
            if depth > self.max_distance:
                self.get_logger().debug(f'æª¢æ¸¬æ¡†{i}è·é›¢å¤ªé : {depth:.2f}m > {self.max_distance}m')
                continue
            
            # å¤ªè¿‘æ™‚ç™¼å‡ºè­¦å‘Šä½†ä»ç„¶è¿½è¹¤ï¼ˆé€™æ¨£æ‰èƒ½å¾Œé€€ï¼‰
            if depth < self.min_distance:
                self.get_logger().warn(f'âš ï¸ ç›®æ¨™éå¸¸æ¥è¿‘: {depth:.2f}mï¼Œæ©Ÿå™¨äººæ‡‰å¾Œé€€')
            
            # è¨ˆç®—èˆ‡å½±åƒä¸­å¿ƒçš„è·é›¢
            center_offset = abs(center_x - self.image_width / 2)
            
            valid_targets.append({
                'detection': detection,
                'depth': depth,
                'center_offset': center_offset
            })
            
            self.get_logger().debug(f'æœ‰æ•ˆç›®æ¨™{i}: æ·±åº¦={depth:.2f}m, åç§»={center_offset:.0f}px')
        
        if len(valid_targets) == 0:
            self.get_logger().debug(f'æª¢æ¸¬åˆ°{len(detections)}äººï¼Œä½†ç„¡æœ‰æ•ˆç›®æ¨™')
            return None
        
        # é¸æ“‡æœ€è¿‘çš„ç›®æ¨™
        valid_targets.sort(key=lambda x: (x['depth'], x['center_offset']))
        
        selected = valid_targets[0]
        self.get_logger().debug(f'é¸æ“‡æœ€è¿‘ç›®æ¨™: æ·±åº¦={selected["depth"]:.2f}m')
        
        return selected
    
    def calculate_control_command(self, target):
        """è¨ˆç®—æ§åˆ¶å‘½ä»¤ï¼ˆä¸‰ç´šè‡ªé©æ‡‰å¢ç›Šç³»çµ±ï¼‰"""
        cmd = Twist()
        
        if target is None:
            return cmd
        
        detection = target['detection']
        depth = target['depth']
        center_x = detection['center_x']
        
        # ========== ä¸‰ç´šè‡ªé©æ‡‰å¢ç›Šç³»çµ± ==========
        # æ ¹æ“šè·é›¢èª¿æ•´å¢ç›Šå’Œé€Ÿåº¦é™åˆ¶
        
        # å®šç¾©è·é›¢å€é–“
        EMERGENCY_THRESHOLD = self.min_distance  # 0.4m - ç·Šæ€¥å€åŸŸ
        NEAR_THRESHOLD = 0.7                      # 0.7m - è¿‘è·é›¢é–¾å€¼
        
        if depth < EMERGENCY_THRESHOLD:
            # ğŸš¨ ç·Šæ€¥å¾Œé€€æ¨¡å¼ (<0.4m)ï¼šå¿«é€Ÿå¾Œé€€ï¼Œå…è¨±æ›´é«˜é€Ÿåº¦
            adaptive_linear_gain = 0.6        # é«˜å¢ç›Šå¿«é€Ÿå¾Œé€€
            adaptive_angular_gain = 1.2       # è¶…é«˜è½‰å‘å¢ç›Š
            max_linear = 0.8                  # æé«˜å¾Œé€€é€Ÿåº¦é™åˆ¶ï¼ˆ0.5â†’0.8ï¼‰
            max_angular = 0.6                 # æé«˜è½‰å‘é€Ÿåº¦é™åˆ¶
            mode = "ğŸš¨ç·Šæ€¥å¾Œé€€"
            
        elif depth <= NEAR_THRESHOLD:
            # è¿‘è·é›¢æ¨¡å¼ (0.4-0.7m)ï¼šæ…¢é€Ÿå‰å¾Œï¼Œå¿«é€Ÿè½‰å‘
            adaptive_linear_gain = 0.25
            adaptive_angular_gain = 0.98
            max_linear = self.max_linear_speed   # 0.3
            max_angular = 0.7                    # æé«˜åˆ° 0.7 rad/sï¼ˆæ›´éˆæ´»çš„è½‰å‘ï¼‰
            mode = "è¿‘è·é›¢"
            
        else:
            # é è·é›¢æ¨¡å¼ (>0.7m)ï¼šå¿«é€Ÿæ¥è¿‘
            adaptive_linear_gain = self.linear_gain   # 0.35
            adaptive_angular_gain = self.angular_gain  # 0.85
            max_linear = 0.5                  # æé«˜é€Ÿåº¦é™åˆ¶ï¼ˆ0.3â†’0.5ï¼‰è®“æ©Ÿå™¨äººèƒ½è·Ÿä¸Š
            max_angular = self.max_angular_speed
            mode = "é è·é›¢"
        
        # è¨˜éŒ„æ¨¡å¼åˆ‡æ›ï¼ˆåƒ…åœ¨æ”¹è®Šæ™‚ï¼‰
        if not hasattr(self, '_last_mode') or self._last_mode != mode:
            self.get_logger().info(
                f'ğŸ”„ åˆ‡æ›åˆ°{mode}æ¨¡å¼ï¼šlinear={adaptive_linear_gain}, angular={adaptive_angular_gain}, '
                f'max_linear={max_linear:.1f}, max_angular={max_angular:.1f}'
            )
            self._last_mode = mode
        
        # ========== ç·šé€Ÿåº¦æ§åˆ¶ï¼ˆå‰å¾Œç§»å‹•ï¼‰==========
        distance_error = depth - self.target_distance
        linear_velocity = adaptive_linear_gain * distance_error
        
        # ä½¿ç”¨å‹•æ…‹é€Ÿåº¦é™åˆ¶
        linear_velocity = np.clip(linear_velocity, -max_linear, max_linear)
        
        # æ­»å€ï¼šÂ±5cm å…§ä¸å‹•ï¼ˆä½†ç·Šæ€¥æ¨¡å¼ä¸‹ç¸®å°æ­»å€ï¼‰
        deadzone = 0.02 if depth < EMERGENCY_THRESHOLD else 0.05
        if abs(distance_error) < deadzone:
            linear_velocity = 0.0
        
        # ========== è§’é€Ÿåº¦æ§åˆ¶ï¼ˆå·¦å³è½‰å‘ï¼‰==========
        center_offset = (center_x - self.image_width / 2) / (self.image_width / 2)
        angular_velocity = -adaptive_angular_gain * center_offset
        
        # ä½¿ç”¨å‹•æ…‹é€Ÿåº¦é™åˆ¶
        angular_velocity = np.clip(angular_velocity, -max_angular, max_angular)
        
        # æ­»å€ï¼šÂ±10% ç•«é¢å¯¬åº¦å…§ä¸è½‰ï¼ˆé¿å…æ“ºå‹•ï¼‰
        if abs(center_offset) < 0.1:
            angular_velocity = 0.0
        
        # ========== è¼¸å‡ºæ§åˆ¶å‘½ä»¤ ==========
        cmd.linear.x = linear_velocity
        cmd.angular.z = angular_velocity
        
        # èª¿è©¦ä¿¡æ¯ï¼ˆç·Šæ€¥æ¨¡å¼ä¸‹å¼·åˆ¶é¡¯ç¤ºï¼‰
        if depth < EMERGENCY_THRESHOLD:
            self.get_logger().warn(
                f'{mode}: è·é›¢={depth:.2f}mâ— èª¤å·®={distance_error:.2f}m, '
                f'å¾Œé€€é€Ÿåº¦={linear_velocity:.3f} m/s, è§’é€Ÿåº¦={angular_velocity:.2f}'
            )
        else:
            self.get_logger().debug(
                f'{mode}: è·é›¢={depth:.2f}m, èª¤å·®={distance_error:.2f}m, '
                f'ç·šé€Ÿåº¦={linear_velocity:.2f}, è§’é€Ÿåº¦={angular_velocity:.2f}'
            )
        
        return cmd
    
    def draw_debug_image(self, image, detections, target):
        """ç¹ªè£½é™¤éŒ¯å½±åƒï¼ˆæ”¹é€²ç‰ˆï¼šé¡¯ç¤ºæ‰€æœ‰äººçš„è·é›¢ï¼‰"""
        debug_image = image.copy()
        
        # å…ˆç²å–æ‰€æœ‰æª¢æ¸¬çµæœçš„æ·±åº¦ä¿¡æ¯
        detection_depths = {}
        for i, detection in enumerate(detections):
            center_x = detection['center_x']
            center_y = detection['center_y']
            depth = self.get_depth_at_point(center_x, center_y, self.latest_depth_image)
            detection_depths[i] = depth
        
        # ç¹ªè£½æ‰€æœ‰åµæ¸¬çµæœï¼ˆéç›®æ¨™ï¼‰
        target_detection = target['detection'] if target is not None else None
        
        for i, detection in enumerate(detections):
            x, y, w, h = detection['bbox']
            confidence = detection['confidence']
            depth = detection_depths[i]
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºç›®æ¨™
            is_target = (target_detection is not None and 
                        detection['center_x'] == target_detection['center_x'] and
                        detection['center_y'] == target_detection['center_y'])
            
            if not is_target:
                # å…¶ä»–äººï¼šç°è‰²æ¡† + é¡¯ç¤ºè·é›¢
                cv2.rectangle(debug_image, (x, y), (x + w, y + h), (128, 128, 128), 2)
                
                # é¡¯ç¤ºä¿¡å¿ƒåˆ†æ•¸å’Œè·é›¢
                label = f'Person {confidence:.2f}'
                if depth is not None and depth > 0:
                    label += f' | {depth:.2f}m'
                
                cv2.putText(debug_image, label, (x, y - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 2)
        
        # ç¹ªè£½é¸ä¸­çš„ç›®æ¨™ï¼ˆæœ€è¿‘çš„äººï¼‰
        if target is not None:
            detection = target['detection']
            depth = target['depth']
            x, y, w, h = detection['bbox']
            center_x = detection['center_x']
            center_y = detection['center_y']
            confidence = detection['confidence']
            
            # ç¶ è‰²ç²—æ¡†æ¨™ç¤ºç›®æ¨™
            cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 255, 0), 3)
            
            # é¡¯ç¤ºã€Œç›®æ¨™ã€æ¨™ç±¤å’Œè·é›¢
            label = f'TARGET {confidence:.2f} | {depth:.2f}m'
            cv2.putText(debug_image, label, (x, y - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # æ¨™ç¤ºã€Œæœ€è¿‘ã€
            cv2.putText(debug_image, 'CLOSEST', (x, y - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # æ¨™ç¤ºç›®æ¨™ä¸­å¿ƒé»
            cv2.circle(debug_image, (center_x, center_y), 5, (0, 0, 255), -1)
            
            # ç¹ªè£½æŒ‡å‘ç›®æ¨™çš„ç®­é ­ï¼ˆå¾ç•«é¢ä¸­å¿ƒï¼‰
            cv2.arrowedLine(debug_image, 
                          (self.image_width // 2, self.image_height - 50),
                          (center_x, center_y),
                          (0, 255, 0), 2, tipLength=0.2)
        
        # ç¹ªè£½å½±åƒä¸­å¿ƒç·š
        cv2.line(debug_image, (self.image_width // 2, 0),
                (self.image_width // 2, self.image_height), (255, 0, 0), 2)
        
        # é¡¯ç¤ºç‹€æ…‹å’Œçµ±è¨ˆä¿¡æ¯
        status_text = 'TRACKING (YOLO)' if target is not None else 'SEARCHING (YOLO)'
        color = (0, 255, 0) if target is not None else (0, 0, 255)
        cv2.putText(debug_image, status_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)
        
        # é¡¯ç¤ºåµæ¸¬åˆ°çš„äººæ•¸
        people_count = len(detections)
        cv2.putText(debug_image, f'Detected: {people_count} people', (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # å¦‚æœæœ‰ç›®æ¨™ï¼Œé¡¯ç¤ºç›®æ¨™è·é›¢ï¼ˆå¤§å­—ï¼‰
        if target is not None:
            distance_text = f'Distance: {target["depth"]:.2f}m'
            cv2.putText(debug_image, distance_text, (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        return debug_image
    
    def process_callback(self):
        """ä¸»è™•ç†å›èª¿"""
        if self.latest_color_image is None or self.latest_depth_image is None:
            return
        
        try:
            # YOLOv8äººé«”åµæ¸¬
            detections = self.detect_people_yolo(self.latest_color_image)
            
            # é¸æ“‡ç›®æ¨™
            target = self.select_target_person(detections, self.latest_depth_image)
            
            # è¨ˆç®—æ§åˆ¶å‘½ä»¤
            if target is not None:
                self.last_detection_time = time.time()
                
                if self.enable_follower:
                    cmd = self.calculate_control_command(target)
                    self.cmd_vel_pub.publish(cmd)
                    
                    status_msg = String()
                    status_msg.data = f'TRACKING: {target["depth"]:.2f}m'
                    self.status_pub.publish(status_msg)
                    
                    self.get_logger().info(
                        f'ğŸ¯ è¿½è¹¤ç›®æ¨™ | è·é›¢: {target["depth"]:.2f}m | '
                        f'ç·šé€Ÿåº¦: {cmd.linear.x:.2f} | è§’é€Ÿåº¦: {cmd.angular.z:.2f}',
                        throttle_duration_sec=1.0
                    )
            else:
                time_since_detection = time.time() - self.last_detection_time
                
                if time_since_detection > self.no_person_timeout:
                    cmd = Twist()
                    self.cmd_vel_pub.publish(cmd)
                    
                    status_msg = String()
                    status_msg.data = 'SEARCHING'
                    self.status_pub.publish(status_msg)
                    
                    self.get_logger().info('ğŸ” æœªåµæ¸¬åˆ°ç›®æ¨™ï¼Œæ©Ÿå™¨äººå·²åœæ­¢',
                                         throttle_duration_sec=2.0)
            
            # ç™¼ä½ˆé™¤éŒ¯å½±åƒ
            if self.publish_debug_image:
                debug_image = self.draw_debug_image(
                    self.latest_color_image, detections, target
                )
                debug_msg = self.bridge.cv2_to_imgmsg(debug_image, 'bgr8')
                self.debug_image_pub.publish(debug_msg)
                
        except Exception as e:
            self.get_logger().error(f'è™•ç†éŒ¯èª¤: {e}')


def main(args=None):
    rclpy.init(args=args)
    node = PeopleFollowerYOLO()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        cmd = Twist()
        node.cmd_vel_pub.publish(cmd)
        node.get_logger().info('ğŸ›‘ YOLOv8äººé«”è¿½è¹¤ç¯€é»å·²åœæ­¢')
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()

