#!/usr/bin/env python3
"""
RealSenseäººé«”è¿½è¹¤ç¯€é»
åŠŸèƒ½ï¼šä½¿ç”¨RealSenseç›¸æ©Ÿåµæ¸¬äººä¸¦æ§åˆ¶æ©Ÿå™¨äººè¿½è¹¤

è¨‚é–±è©±é¡Œï¼š
  - /camera/color/image_raw (RGBå½±åƒ)
  - /camera/aligned_depth_to_color/image_raw (å°é½Šçš„æ·±åº¦å½±åƒ)
  - /camera/color/camera_info (ç›¸æ©Ÿåƒæ•¸)

ç™¼ä½ˆè©±é¡Œï¼š
  - /cmd_vel (æ§åˆ¶æ©Ÿå™¨äººé‹å‹•)
  - /people_follower/debug_image (é™¤éŒ¯è¦–è¦ºåŒ–å½±åƒ)
  - /people_follower/status (è¿½è¹¤ç‹€æ…‹)
"""

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import Twist
from std_msgs.msg import String
from cv_bridge import CvBridge
import cv2
import numpy as np
import time


class PeopleFollowerNode(Node):
    """äººé«”è¿½è¹¤ç¯€é»"""
    
    def __init__(self):
        super().__init__('people_follower_node')
        
        # ========== åƒæ•¸å®£å‘Š ==========
        self.declare_parameter('detection_method', 'hog')  # 'hog', 'dnn', 'mediapipe'
        self.declare_parameter('target_distance', 1.0)     # ç›®æ¨™è¿½è¹¤è·é›¢(å…¬å°º)
        self.declare_parameter('min_distance', 0.5)        # æœ€å°å®‰å…¨è·é›¢(å…¬å°º)
        self.declare_parameter('max_distance', 3.0)        # æœ€å¤§åµæ¸¬è·é›¢(å…¬å°º)
        self.declare_parameter('max_linear_speed', 0.3)    # æœ€å¤§å‰é€²é€Ÿåº¦(m/s)
        self.declare_parameter('max_angular_speed', 0.8)   # æœ€å¤§æ—‹è½‰é€Ÿåº¦(rad/s)
        self.declare_parameter('linear_gain', 0.5)         # ç·šé€Ÿåº¦å¢ç›Š
        self.declare_parameter('angular_gain', 2.0)        # è§’é€Ÿåº¦å¢ç›Š
        self.declare_parameter('enable_follower', True)    # æ˜¯å¦å•Ÿç”¨è¿½è¹¤
        self.declare_parameter('publish_debug_image', True) # æ˜¯å¦ç™¼ä½ˆé™¤éŒ¯å½±åƒ
        
        # ç²å–åƒæ•¸
        self.detection_method = self.get_parameter('detection_method').value
        self.target_distance = self.get_parameter('target_distance').value
        self.min_distance = self.get_parameter('min_distance').value
        self.max_distance = self.get_parameter('max_distance').value
        self.max_linear_speed = self.get_parameter('max_linear_speed').value
        self.max_angular_speed = self.get_parameter('max_angular_speed').value
        self.linear_gain = self.get_parameter('linear_gain').value
        self.angular_gain = self.get_parameter('angular_gain').value
        self.enable_follower = self.get_parameter('enable_follower').value
        self.publish_debug_image = self.get_parameter('publish_debug_image').value
        
        # ========== åˆå§‹åŒ–è®Šæ•¸ ==========
        self.bridge = CvBridge()
        self.latest_color_image = None
        self.latest_depth_image = None
        self.camera_info = None
        self.image_width = 640
        self.image_height = 480
        self.last_detection_time = time.time()
        self.no_person_timeout = 2.0  # æœªåµæ¸¬åˆ°äººçš„è¶…æ™‚æ™‚é–“(ç§’)
        
        # ========== åˆå§‹åŒ–äººé«”åµæ¸¬å™¨ ==========
        self.init_detector()
        
        # ========== QoSè¨­ç½® ==========
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            history=HistoryPolicy.KEEP_LAST,
            depth=1
        )
        
        # ========== è¨‚é–±è€… ==========
        self.color_sub = self.create_subscription(
            Image,
            '/camera/camera/color/image_raw',
            self.color_callback,
            qos_profile
        )
        
        self.depth_sub = self.create_subscription(
            Image,
            '/camera/camera/aligned_depth_to_color/image_raw',
            self.depth_callback,
            qos_profile
        )
        
        self.camera_info_sub = self.create_subscription(
            CameraInfo,
            '/camera/camera/color/camera_info',
            self.camera_info_callback,
            10
        )
        
        # ========== ç™¼ä½ˆè€… ==========
        self.cmd_vel_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        self.debug_image_pub = self.create_publisher(Image, '/people_follower/debug_image', 10)
        self.status_pub = self.create_publisher(String, '/people_follower/status', 10)
        
        # ========== å®šæ™‚å™¨ ==========
        self.timer = self.create_timer(0.1, self.process_callback)  # 10Hz
        
        self.get_logger().info('ğŸš€ äººé«”è¿½è¹¤ç¯€é»å·²å•Ÿå‹•')
        self.get_logger().info(f'   åµæ¸¬æ–¹æ³•: {self.detection_method}')
        self.get_logger().info(f'   ç›®æ¨™è·é›¢: {self.target_distance}m')
        self.get_logger().info(f'   è¿½è¹¤å•Ÿç”¨: {self.enable_follower}')
    
    def init_detector(self):
        """åˆå§‹åŒ–äººé«”åµæ¸¬å™¨"""
        if self.detection_method == 'hog':
            # HOGåµæ¸¬å™¨ï¼ˆOpenCVå…§å»ºï¼Œç°¡å–®å¿«é€Ÿï¼‰
            self.hog_detector = cv2.HOGDescriptor()
            self.hog_detector.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
            self.get_logger().info('âœ… HOGäººé«”åµæ¸¬å™¨å·²åˆå§‹åŒ–')
            
        elif self.detection_method == 'dnn':
            # DNNåµæ¸¬å™¨ï¼ˆMobileNet-SSDï¼‰
            try:
                # ä½¿ç”¨COCOé è¨“ç·´çš„MobileNet-SSDæ¨¡å‹
                # éœ€è¦ä¸‹è¼‰æ¨¡å‹æª”æ¡ˆï¼ˆå¦‚æœæ²’æœ‰ï¼Œæœƒä½¿ç”¨HOGä½œç‚ºå¾Œå‚™ï¼‰
                model_path = '/home/robotester1/legged_robot/models/MobileNetSSD_deploy.caffemodel'
                config_path = '/home/robotester1/legged_robot/models/MobileNetSSD_deploy.prototxt'
                
                self.net = cv2.dnn.readNetFromCaffe(config_path, model_path)
                self.get_logger().info('âœ… DNNäººé«”åµæ¸¬å™¨å·²åˆå§‹åŒ–')
            except Exception as e:
                self.get_logger().warn(f'âš ï¸ DNNæ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œåˆ‡æ›åˆ°HOG: {e}')
                self.detection_method = 'hog'
                self.init_detector()
        else:
            self.get_logger().warn(f'âš ï¸ æœªçŸ¥åµæ¸¬æ–¹æ³• {self.detection_method}ï¼Œä½¿ç”¨HOG')
            self.detection_method = 'hog'
            self.init_detector()
    
    def color_callback(self, msg):
        """RGBå½±åƒå›èª¿"""
        try:
            self.latest_color_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
            self.image_height, self.image_width = self.latest_color_image.shape[:2]
        except Exception as e:
            self.get_logger().error(f'RGBå½±åƒè½‰æ›å¤±æ•—: {e}')
    
    def depth_callback(self, msg):
        """æ·±åº¦å½±åƒå›èª¿"""
        try:
            # RealSenseæ·±åº¦å½±åƒé€šå¸¸æ˜¯16ä½å…ƒï¼Œå–®ä½ç‚ºæ¯«ç±³
            self.latest_depth_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f'æ·±åº¦å½±åƒè½‰æ›å¤±æ•—: {e}')
    
    def camera_info_callback(self, msg):
        """ç›¸æ©Ÿåƒæ•¸å›èª¿"""
        if self.camera_info is None:
            self.camera_info = msg
            self.get_logger().info('âœ… ç›¸æ©Ÿåƒæ•¸å·²æ¥æ”¶')
    
    def detect_people_hog(self, image):
        """ä½¿ç”¨HOGåµæ¸¬äººé«”"""
        # å½±åƒé è™•ç†ï¼šç›´æ–¹åœ–å‡è¡¡åŒ–æ”¹å–„å°æ¯”åº¦
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)
        gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
        
        # HOGåµæ¸¬å™¨åƒæ•¸ï¼ˆèª¿æ•´ä»¥æ¸›å°‘èª¤æª¢ï¼‰
        # æ³¨æ„ï¼šOpenCV 4.10+ å·²ç§»é™¤ finalThreshold åƒæ•¸
        detections, weights = self.hog_detector.detectMultiScale(
            gray_bgr,
            winStride=(8, 8),
            padding=(8, 8),
            scale=1.05,
            useMeanshiftGrouping=False
        )
        
        results = []
        for i, (x, y, w, h) in enumerate(detections):
            # ç½®ä¿¡åº¦
            try:
                confidence = float(weights[i]) if len(weights) > 0 and i < len(weights) else 1.0
            except:
                confidence = 1.0
            
            # å¤šé‡éæ¿¾æ¢ä»¶æ¸›å°‘èª¤æª¢
            aspect_ratio = h / w if w > 0 else 0
            is_reasonable_size = (h > 100) and (w > 40)
            is_person_like = (1.5 <= aspect_ratio <= 4.0)
            
            # åªä¿ç•™é«˜ç½®ä¿¡åº¦ä¸”ç¬¦åˆäººé«”ç‰¹å¾µçš„åµæ¸¬
            if confidence > 1.0 and is_reasonable_size and is_person_like:
                results.append({
                    'bbox': (x, y, w, h),
                    'confidence': confidence,
                    'center_x': x + w // 2,
                    'center_y': y + h // 2
                })
        
        return results
    
    def detect_people_dnn(self, image):
        """ä½¿ç”¨DNNåµæ¸¬äººé«”ï¼ˆMobileNet-SSDï¼‰"""
        blob = cv2.dnn.blobFromImage(
            cv2.resize(image, (300, 300)),
            0.007843,
            (300, 300),
            127.5
        )
        
        self.net.setInput(blob)
        detections = self.net.forward()
        
        results = []
        h, w = image.shape[:2]
        
        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            class_id = int(detections[0, 0, i, 1])
            
            # Class 15 æ˜¯äººé¡ï¼ˆCOCOè³‡æ–™é›†ï¼‰
            if confidence > 0.5 and class_id == 15:
                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                (x1, y1, x2, y2) = box.astype('int')
                
                results.append({
                    'bbox': (x1, y1, x2 - x1, y2 - y1),
                    'confidence': float(confidence),
                    'center_x': (x1 + x2) // 2,
                    'center_y': (y1 + y2) // 2
                })
        
        return results
    
    def get_depth_at_point(self, x, y, depth_image, window_size=5):
        """ç²å–æŒ‡å®šé»çš„æ·±åº¦å€¼ï¼ˆä½¿ç”¨å‘¨åœè¦–çª—çš„ä¸­å€¼ä»¥æé«˜ç©©å¥æ€§ï¼‰"""
        if depth_image is None:
            return None
        
        h, w = depth_image.shape
        x = np.clip(x, 0, w - 1)
        y = np.clip(y, 0, h - 1)
        
        # ç²å–è¦–çª—å€åŸŸ
        half_window = window_size // 2
        y_min = max(0, y - half_window)
        y_max = min(h, y + half_window + 1)
        x_min = max(0, x - half_window)
        x_max = min(w, x + half_window + 1)
        
        window = depth_image[y_min:y_max, x_min:x_max]
        
        # éæ¿¾ç„¡æ•ˆæ·±åº¦å€¼ï¼ˆ0ï¼‰
        valid_depths = window[window > 0]
        
        if len(valid_depths) == 0:
            return None
        
        # è¿”å›ä¸­å€¼æ·±åº¦ï¼ˆæ¯«ç±³è½‰å…¬å°ºï¼‰
        return np.median(valid_depths) / 1000.0
    
    def select_target_person(self, detections, depth_image):
        """é¸æ“‡ç›®æ¨™äººç‰©ï¼ˆæœ€è¿‘ä¸”åœ¨å½±åƒä¸­å¤®çš„äººï¼Œä½¿ç”¨æ·±åº¦éæ¿¾èª¤æª¢ï¼‰"""
        if len(detections) == 0:
            return None
        
        valid_targets = []
        
        for detection in detections:
            center_x = detection['center_x']
            center_y = detection['center_y']
            bbox = detection['bbox']
            x, y, w, h = bbox
            
            # ç²å–æ·±åº¦ï¼ˆä½¿ç”¨æª¢æ¸¬æ¡†å…§å¤šå€‹é»çš„å¹³å‡æ·±åº¦ï¼‰
            depth_samples = []
            for dy in [h//4, h//2, 3*h//4]:
                for dx in [w//3, w//2, 2*w//3]:
                    d = self.get_depth_at_point(x + dx, y + dy, depth_image)
                    if d is not None and d > 0:
                        depth_samples.append(d)
            
            if len(depth_samples) == 0:
                continue
            
            # ä½¿ç”¨ä¸­å€¼æ·±åº¦ï¼ˆæ›´ç©©å¥ï¼‰
            depth = np.median(depth_samples)
            
            # éæ¿¾è¶…å‡ºç¯„åœçš„åµæ¸¬
            if depth < self.min_distance or depth > self.max_distance:
                continue
            
            # æ·±åº¦ä¸€è‡´æ€§æª¢æŸ¥ï¼ˆåŒä¸€å€‹äººçš„æ·±åº¦æ‡‰è©²ç›¸è¿‘ï¼‰
            depth_std = np.std(depth_samples)
            if depth_std > 0.3:  # æ·±åº¦è®ŠåŒ–å¤ªå¤§ï¼Œå¯èƒ½æ˜¯èª¤æª¢
                continue
            
            # è¨ˆç®—èˆ‡å½±åƒä¸­å¿ƒçš„è·é›¢ï¼ˆç”¨æ–¼é¸æ“‡ä¸­å¤®çš„äººï¼‰
            center_offset = abs(center_x - self.image_width / 2)
            
            valid_targets.append({
                'detection': detection,
                'depth': depth,
                'center_offset': center_offset,
                'depth_consistency': depth_std
            })
        
        if len(valid_targets) == 0:
            return None
        
        # é¸æ“‡æœ€è¿‘çš„ç›®æ¨™ï¼ˆå¦‚æœå¤šå€‹ç›®æ¨™è·é›¢ç›¸è¿‘ï¼Œé¸æ“‡æ›´é è¿‘ä¸­å¤®çš„ï¼‰
        valid_targets.sort(key=lambda x: (x['depth'], x['center_offset']))
        
        return valid_targets[0]
    
    def calculate_control_command(self, target):
        """è¨ˆç®—æ§åˆ¶å‘½ä»¤"""
        cmd = Twist()
        
        if target is None:
            # æ²’æœ‰ç›®æ¨™ï¼Œåœæ­¢
            return cmd
        
        detection = target['detection']
        depth = target['depth']
        center_x = detection['center_x']
        
        # ========== ç·šé€Ÿåº¦æ§åˆ¶ ==========
        # è·é›¢èª¤å·®
        distance_error = depth - self.target_distance
        
        # æ¯”ä¾‹æ§åˆ¶
        linear_velocity = self.linear_gain * distance_error
        
        # é™åˆ¶é€Ÿåº¦
        linear_velocity = np.clip(
            linear_velocity,
            -self.max_linear_speed,
            self.max_linear_speed
        )
        
        # æ­»å€æ§åˆ¶ï¼ˆé¿å…æŠ–å‹•ï¼‰
        if abs(distance_error) < 0.1:
            linear_velocity = 0.0
        
        # ========== è§’é€Ÿåº¦æ§åˆ¶ ==========
        # è¨ˆç®—ç›®æ¨™åœ¨å½±åƒä¸­çš„åç§»ï¼ˆæ­£è¦åŒ–åˆ°[-1, 1]ï¼‰
        center_offset = (center_x - self.image_width / 2) / (self.image_width / 2)
        
        # æ¯”ä¾‹æ§åˆ¶
        angular_velocity = -self.angular_gain * center_offset
        
        # é™åˆ¶é€Ÿåº¦
        angular_velocity = np.clip(
            angular_velocity,
            -self.max_angular_speed,
            self.max_angular_speed
        )
        
        # æ­»å€æ§åˆ¶
        if abs(center_offset) < 0.1:
            angular_velocity = 0.0
        
        # ========== è¨­å®šå‘½ä»¤ ==========
        cmd.linear.x = linear_velocity
        cmd.angular.z = angular_velocity
        
        return cmd
    
    def draw_debug_image(self, image, detections, target):
        """ç¹ªè£½é™¤éŒ¯å½±åƒ"""
        debug_image = image.copy()
        
        # ç¹ªè£½æ‰€æœ‰åµæ¸¬çµæœ
        for detection in detections:
            x, y, w, h = detection['bbox']
            confidence = detection['confidence']
            
            # ç°è‰²æ¡†è¡¨ç¤ºåµæ¸¬åˆ°ä½†æœªé¸ä¸­çš„äºº
            cv2.rectangle(debug_image, (x, y), (x + w, y + h), (128, 128, 128), 2)
            cv2.putText(
                debug_image,
                f'{confidence:.2f}',
                (x, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (128, 128, 128),
                2
            )
        
        # ç¹ªè£½é¸ä¸­çš„ç›®æ¨™
        if target is not None:
            detection = target['detection']
            depth = target['depth']
            x, y, w, h = detection['bbox']
            center_x = detection['center_x']
            center_y = detection['center_y']
            
            # ç¶ è‰²æ¡†è¡¨ç¤ºè¿½è¹¤ç›®æ¨™
            cv2.rectangle(debug_image, (x, y), (x + w, y + h), (0, 255, 0), 3)
            
            # é¡¯ç¤ºè·é›¢è³‡è¨Š
            text = f'Target: {depth:.2f}m'
            cv2.putText(
                debug_image,
                text,
                (x, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (0, 255, 0),
                2
            )
            
            # ç¹ªè£½ä¸­å¿ƒé»
            cv2.circle(debug_image, (center_x, center_y), 5, (0, 0, 255), -1)
        
        # ç¹ªè£½å½±åƒä¸­å¿ƒç·š
        cv2.line(
            debug_image,
            (self.image_width // 2, 0),
            (self.image_width // 2, self.image_height),
            (255, 0, 0),
            2
        )
        
        # é¡¯ç¤ºç‹€æ…‹è³‡è¨Š
        status_text = 'TRACKING' if target is not None else 'SEARCHING'
        color = (0, 255, 0) if target is not None else (0, 0, 255)
        cv2.putText(
            debug_image,
            status_text,
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.0,
            color,
            2
        )
        
        return debug_image
    
    def process_callback(self):
        """ä¸»è™•ç†å›èª¿"""
        # æª¢æŸ¥æ˜¯å¦æœ‰å½±åƒè³‡æ–™
        if self.latest_color_image is None or self.latest_depth_image is None:
            return
        
        try:
            # ========== äººé«”åµæ¸¬ ==========
            if self.detection_method == 'hog':
                detections = self.detect_people_hog(self.latest_color_image)
            elif self.detection_method == 'dnn':
                detections = self.detect_people_dnn(self.latest_color_image)
            else:
                detections = []
            
            # ========== é¸æ“‡ç›®æ¨™ ==========
            target = self.select_target_person(detections, self.latest_depth_image)
            
            # ========== è¨ˆç®—æ§åˆ¶å‘½ä»¤ ==========
            if target is not None:
                self.last_detection_time = time.time()
                
                if self.enable_follower:
                    cmd = self.calculate_control_command(target)
                    self.cmd_vel_pub.publish(cmd)
                    
                    # ç™¼ä½ˆç‹€æ…‹
                    status_msg = String()
                    status_msg.data = f'TRACKING: {target["depth"]:.2f}m'
                    self.status_pub.publish(status_msg)
                    
                    self.get_logger().info(
                        f'ğŸ¯ è¿½è¹¤ç›®æ¨™ | è·é›¢: {target["depth"]:.2f}m | '
                        f'ç·šé€Ÿåº¦: {cmd.linear.x:.2f} | è§’é€Ÿåº¦: {cmd.angular.z:.2f}',
                        throttle_duration_sec=1.0
                    )
            else:
                # æª¢æŸ¥è¶…æ™‚
                time_since_detection = time.time() - self.last_detection_time
                
                if time_since_detection > self.no_person_timeout:
                    # è¶…æ™‚ï¼Œåœæ­¢æ©Ÿå™¨äºº
                    cmd = Twist()
                    self.cmd_vel_pub.publish(cmd)
                    
                    # ç™¼ä½ˆç‹€æ…‹
                    status_msg = String()
                    status_msg.data = 'SEARCHING'
                    self.status_pub.publish(status_msg)
                    
                    self.get_logger().info(
                        'ğŸ” æœªåµæ¸¬åˆ°ç›®æ¨™ï¼Œæ©Ÿå™¨äººå·²åœæ­¢',
                        throttle_duration_sec=2.0
                    )
            
            # ========== ç™¼ä½ˆé™¤éŒ¯å½±åƒ ==========
            if self.publish_debug_image:
                debug_image = self.draw_debug_image(
                    self.latest_color_image,
                    detections,
                    target
                )
                debug_msg = self.bridge.cv2_to_imgmsg(debug_image, 'bgr8')
                self.debug_image_pub.publish(debug_msg)
                
        except Exception as e:
            self.get_logger().error(f'è™•ç†éŒ¯èª¤: {e}')


def main(args=None):
    rclpy.init(args=args)
    node = PeopleFollowerNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        # ç™¼é€åœæ­¢å‘½ä»¤
        cmd = Twist()
        node.cmd_vel_pub.publish(cmd)
        node.get_logger().info('ğŸ›‘ äººé«”è¿½è¹¤ç¯€é»å·²åœæ­¢')
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
